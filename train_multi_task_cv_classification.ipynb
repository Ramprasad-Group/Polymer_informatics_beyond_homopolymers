{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data set\n",
    "\n",
    "1. Load data set\n",
    "2. 20%/ 80% split, 80% for cross-validation, 20% for training the meta learner (later)\n",
    "3. Scale values \n",
    "4. Convert to tensoflow data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('classification_dataset.pkl')\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fps_blend_comp'] = (np.vstack(df.fps_blend_comp) - 1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fps_blend_comp'] = (np.around(np.vstack(df.fps_blend_comp),decimals=5 )).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['prop'] != 'Td']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['miscibility'] = np.array(df.val_1.values == df.val_2.values).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(0, 'selector', pd.get_dummies(df.prop).values.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selector</th>\n",
       "      <th>fps_blend_comp</th>\n",
       "      <th>bdid</th>\n",
       "      <th>c1</th>\n",
       "      <th>prop</th>\n",
       "      <th>val_1</th>\n",
       "      <th>val_2</th>\n",
       "      <th>miscibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0.20375, 0.85296, 0.12903, 0.27517, 0.25, 0.4...</td>\n",
       "      <td>547</td>\n",
       "      <td>0.80</td>\n",
       "      <td>Tg</td>\n",
       "      <td>238.15</td>\n",
       "      <td>238.15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0.26403, 0.66891, 0.07692, 0.19685, 0.14286, ...</td>\n",
       "      <td>547</td>\n",
       "      <td>0.50</td>\n",
       "      <td>Tg</td>\n",
       "      <td>248.15</td>\n",
       "      <td>248.15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0.2232, 0.78726, 0.11111, 0.24795, 0.21212, 0...</td>\n",
       "      <td>547</td>\n",
       "      <td>0.70</td>\n",
       "      <td>Tg</td>\n",
       "      <td>249.15</td>\n",
       "      <td>249.15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0.26403, 0.66891, 0.07692, 0.19685, 0.14286, ...</td>\n",
       "      <td>547</td>\n",
       "      <td>0.50</td>\n",
       "      <td>Tg</td>\n",
       "      <td>338.15</td>\n",
       "      <td>338.15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0.20375, 0.85296, 0.12903, 0.27517, 0.25, 0.4...</td>\n",
       "      <td>547</td>\n",
       "      <td>0.80</td>\n",
       "      <td>Tg</td>\n",
       "      <td>342.15</td>\n",
       "      <td>342.15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4244</th>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.24404, 0.5775, 0.0, 0.07748, 0.0, 0.7198, 0...</td>\n",
       "      <td>2151</td>\n",
       "      <td>0.28</td>\n",
       "      <td>Tm</td>\n",
       "      <td>421.75</td>\n",
       "      <td>421.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4245</th>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.18245, 0.58736, 0.0, 0.23073, 0.0, 0.5371, ...</td>\n",
       "      <td>2151</td>\n",
       "      <td>0.73</td>\n",
       "      <td>Tm</td>\n",
       "      <td>422.65</td>\n",
       "      <td>422.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4246</th>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.20499, 0.58362, 0.0, 0.16797, 0.0, 0.60137,...</td>\n",
       "      <td>2151</td>\n",
       "      <td>0.56</td>\n",
       "      <td>Tm</td>\n",
       "      <td>422.75</td>\n",
       "      <td>422.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4247</th>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.21712, 0.60635, 0.0, 0.14943, 0.00689, 0.63...</td>\n",
       "      <td>2152</td>\n",
       "      <td>0.52</td>\n",
       "      <td>Tm</td>\n",
       "      <td>424.25</td>\n",
       "      <td>424.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4248</th>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.24132, 0.59341, 0.0, 0.08992, 0.00436, 0.71...</td>\n",
       "      <td>2152</td>\n",
       "      <td>0.33</td>\n",
       "      <td>Tm</td>\n",
       "      <td>425.25</td>\n",
       "      <td>425.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4249 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     selector                                     fps_blend_comp  bdid    c1  \\\n",
       "0      [1, 0]  [0.20375, 0.85296, 0.12903, 0.27517, 0.25, 0.4...   547  0.80   \n",
       "1      [1, 0]  [0.26403, 0.66891, 0.07692, 0.19685, 0.14286, ...   547  0.50   \n",
       "2      [1, 0]  [0.2232, 0.78726, 0.11111, 0.24795, 0.21212, 0...   547  0.70   \n",
       "3      [1, 0]  [0.26403, 0.66891, 0.07692, 0.19685, 0.14286, ...   547  0.50   \n",
       "4      [1, 0]  [0.20375, 0.85296, 0.12903, 0.27517, 0.25, 0.4...   547  0.80   \n",
       "...       ...                                                ...   ...   ...   \n",
       "4244   [0, 1]  [0.24404, 0.5775, 0.0, 0.07748, 0.0, 0.7198, 0...  2151  0.28   \n",
       "4245   [0, 1]  [0.18245, 0.58736, 0.0, 0.23073, 0.0, 0.5371, ...  2151  0.73   \n",
       "4246   [0, 1]  [0.20499, 0.58362, 0.0, 0.16797, 0.0, 0.60137,...  2151  0.56   \n",
       "4247   [0, 1]  [0.21712, 0.60635, 0.0, 0.14943, 0.00689, 0.63...  2152  0.52   \n",
       "4248   [0, 1]  [0.24132, 0.59341, 0.0, 0.08992, 0.00436, 0.71...  2152  0.33   \n",
       "\n",
       "     prop   val_1   val_2  miscibility  \n",
       "0      Tg  238.15  238.15            1  \n",
       "1      Tg  248.15  248.15            1  \n",
       "2      Tg  249.15  249.15            1  \n",
       "3      Tg  338.15  338.15            1  \n",
       "4      Tg  342.15  342.15            1  \n",
       "...   ...     ...     ...          ...  \n",
       "4244   Tm  421.75  421.75            1  \n",
       "4245   Tm  422.65  422.65            1  \n",
       "4246   Tm  422.75  422.75            1  \n",
       "4247   Tm  424.25  424.25            1  \n",
       "4248   Tm  425.25  425.25            1  \n",
       "\n",
       "[4249 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import QuantileTransformer, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(123)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# df['value'] = df.apply(lambda x: list([x['val_1'],\n",
    "#                                         x['val_2']]),axis=1)    \n",
    "\n",
    "df = df.sample(frac=1, random_state=123)\n",
    "target_property_scaler = MinMaxScaler\n",
    "\n",
    "batch_size = 200\n",
    "\n",
    "# df['scaled_value'] = df['value']\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "props = df.prop.unique().tolist()\n",
    "\n",
    "datasets = []\n",
    "def get_dataset(df):\n",
    "    fps_blends = np.stack(df.fps_blend_comp.values).astype(np.float32)\n",
    "\n",
    "    selector = np.stack(df.selector.values).astype(np.float32)\n",
    "    target = df.miscibility.values.astype(int)[:, np.newaxis]\n",
    "    bdid = np.stack(df.bdid.values).astype(np.str)[:, np.newaxis]\n",
    "    # miscibility = df.miscibility.values.astype(int)[:, np.newaxis]\n",
    "    c1 = df.c1.values.astype(np.float32)[:, np.newaxis]\n",
    "    # type_poly = np.stack(df.type.values).astype(np.str)[:, np.newaxis]\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(({'selector': selector, 'fps_blends': fps_blends, 'prop': df.prop, 'c1': c1, 'bdid':bdid}, target))\n",
    "\n",
    "\n",
    "    dataset = dataset.cache().batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "training_df, test_df = train_test_split(df, test_size=0.2, stratify=df.prop, random_state=123)\n",
    "training_df, test_df = training_df.copy(), test_df.copy()\n",
    "# print(props)\n",
    "# print(skf.split(training_df, training_df.prop))\n",
    "for train_index, val_index in skf.split(training_df, training_df.prop):\n",
    "    \n",
    "    train_df = training_df.iloc[train_index].copy()\n",
    "    val_df = training_df.iloc[val_index].copy()\n",
    "    datasets.append({'train': get_dataset(train_df), 'val': get_dataset(val_df)})\n",
    "\n",
    "    \n",
    "datasets_final = {'train': get_dataset(training_df), 'test': get_dataset(test_df)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <PrefetchDataset element_spec=({'selector': TensorSpec(shape=(None, 2), dtype=tf.float32, name=None), 'fps_blends': TensorSpec(shape=(None, 872), dtype=tf.float32, name=None), 'prop': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'c1': TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), 'bdid': TensorSpec(shape=(None, 1), dtype=tf.string, name=None)}, TensorSpec(shape=(None, 1), dtype=tf.int64, name=None))>,\n",
       " 'test': <PrefetchDataset element_spec=({'selector': TensorSpec(shape=(None, 2), dtype=tf.float32, name=None), 'fps_blends': TensorSpec(shape=(None, 872), dtype=tf.float32, name=None), 'prop': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'c1': TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), 'bdid': TensorSpec(shape=(None, 1), dtype=tf.string, name=None)}, TensorSpec(shape=(None, 1), dtype=tf.int64, name=None))>}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras as tfk\n",
    "import tensorflow as tf\n",
    "from datetime import datetime \n",
    "from tensorflow.python.keras.engine import data_adapter\n",
    "from keras_tuner import HyperModel\n",
    "from keras_tuner.tuners import Hyperband, RandomSearch\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "\n",
    "class PropertyDonwsteam(tfk.Model):\n",
    "    def __init__(self, hp):\n",
    "        super().__init__()\n",
    "        self.my_layers = []\n",
    "        self.concat_at = hp.Int('concat_at', 0, 2)\n",
    "        \n",
    "        for i in range(hp.Int('num_layers', 3, 3)): \n",
    "            new_step = [               \n",
    "            tf.keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                            min_value=352,\n",
    "                                            max_value=544,\n",
    "                                            step=64),),\n",
    "            \n",
    "            tf.keras.layers.PReLU(),\n",
    "            tf.keras.layers.Dropout(hp.Float(\n",
    "                'dropout_' + str(i),\n",
    "                min_value=0.0,\n",
    "                max_value=0.5,\n",
    "                default=0.25,\n",
    "                step=0.1,\n",
    "            )),\n",
    "            ]\n",
    "\n",
    "            self.my_layers.append(new_step)\n",
    "        self.my_layers.append([tf.keras.layers.Dense(1, activation = 'sigmoid')])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs['fps_blends']\n",
    "\n",
    "        for num, layer_step in enumerate(self.my_layers):\n",
    "            if self.concat_at == num:\n",
    "                x = tf.concat((x, inputs['selector']), -1)\n",
    "\n",
    "            for layer in layer_step:\n",
    "                x = layer(x)\n",
    "    \n",
    "        return x\n",
    "    \n",
    "    def predict_step(self, data):\n",
    "        data = data_adapter.expand_1d(data)\n",
    "        x, _, _ = data_adapter.unpack_x_y_sample_weight(data)\n",
    "        # drop prop here\n",
    "        prop = x['prop']\n",
    "        del x['prop']\n",
    "        return self(x, training=False), data[-1], prop\n",
    "\n",
    "    \n",
    "def build_model(hp):\n",
    "    model = PropertyDonwsteam(hp)\n",
    "    opt = tf.keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate',\n",
    "                      values=[1e-3]))\n",
    "    opt = tfa.optimizers.SWA(opt)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        loss=keras.losses.BinaryCrossentropy(from_logits=False),)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization of all of the five cross-validattion models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "results, property_metric, best_values= [], [], []\n",
    "\n",
    "prec_Tg = []\n",
    "recall_Tg = []\n",
    "accuracy_Tg = []\n",
    "prec_Tm = []\n",
    "recall_Tm = []\n",
    "accuracy_Tm = []\n",
    "for num, data in enumerate(datasets):\n",
    "    \n",
    "    tuner = Hyperband(\n",
    "        build_model,\n",
    "        objective='val_loss',\n",
    "        max_epochs=300,\n",
    "        seed=10,\n",
    "        directory=f'hyperparameter_search_final_classification',\n",
    "        project_name='fold_' + str(num)\n",
    "        )\n",
    "\n",
    "    reduce_lr = tfk.callbacks.ReduceLROnPlateau(\n",
    "        factor=0.8,\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=1,\n",
    "    )\n",
    "    \n",
    "    earlystop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=40)\n",
    "    \n",
    "    class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
    "        def on_train_end(*args, **kwargs):\n",
    "            IPython.display.clear_output(wait = True)\n",
    "    \n",
    "    # Create an instance of the model\n",
    "    tuner.search(data['train'],\n",
    "                epochs=300,\n",
    "                validation_data=data['val'],\n",
    "                callbacks=[earlystop, reduce_lr, ClearTrainingOutput()],\n",
    "                verbose=0\n",
    "                )\n",
    "    \n",
    "    best_values.append(tuner.get_best_hyperparameters()[0].values)\n",
    "    \n",
    "    # Post processing\n",
    "    best_model = tuner.get_best_models(1)[0]\n",
    "    res = np.concatenate(best_model.predict(data['val']), -1)\n",
    "    \n",
    "    best_model.save(f'models/cv_final_class/{num}', include_optimizer=False)\n",
    "\n",
    "    _df = pd.DataFrame(res, columns=['pred', 'target', 'prop'])\n",
    "    _df['prop'] = _df.prop.apply(lambda x: x.decode('utf-8'))\n",
    "    props = _df.prop.unique()\n",
    "   \n",
    "    res_Tg = _df[_df['prop'] == 'Tg']\n",
    "    res_Tm = _df[_df['prop'] == 'Tm']      \n",
    "\n",
    "    y_true = np.array(res_Tm.target.values, dtype = int)\n",
    "    y_scores = res_Tm.pred.values\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_scores, pos_label = 1)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    predicted_value = []\n",
    "    for i in res_Tm.pred.values:\n",
    "        if i > optimal_threshold:\n",
    "            predicted_value.append(1)\n",
    "        else:\n",
    "            predicted_value.append(0)\n",
    "    m = tf.keras.metrics.Precision()\n",
    "    m.update_state(np.array(res_Tm.target.values, dtype = int), predicted_value)\n",
    "    prec_Tm.append(m.result().numpy())\n",
    "    m = tf.keras.metrics.Recall()\n",
    "    m.update_state(np.array(res_Tm.target.values, dtype = int), predicted_value)\n",
    "    recall_Tm.append(m.result().numpy())\n",
    "    m = tf.keras.metrics.Accuracy()\n",
    "    m.update_state(np.array(res_Tm.target.values, dtype = int), predicted_value)\n",
    "    accuracy_Tm.append(m.result().numpy())\n",
    "\n",
    "    y_true = np.array(res_Tg.target.values, dtype = int)\n",
    "    y_scores = res_Tg.pred.values\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_scores, pos_label = 1)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    predicted_value = []\n",
    "    for i in res_Tg.pred.values:\n",
    "        if i > optimal_threshold:\n",
    "            predicted_value.append(1)\n",
    "        else:\n",
    "            predicted_value.append(0)\n",
    "    m = tf.keras.metrics.Precision()\n",
    "    m.update_state(np.array(res_Tg.target.values, dtype = int), predicted_value)\n",
    "    prec_Tg.append(m.result().numpy())\n",
    "    m = tf.keras.metrics.Recall()\n",
    "    m.update_state(np.array(res_Tg.target.values, dtype = int), predicted_value)\n",
    "    recall_Tg.append(m.result().numpy())\n",
    "    m = tf.keras.metrics.Accuracy()\n",
    "    m.update_state(np.array(res_Tg.target.values, dtype = int), predicted_value)\n",
    "    accuracy_Tg.append(m.result().numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_performance = pd.DataFrame({'prec_Tg' :prec_Tg, 'recall_Tg' : recall_Tg, 'accuracy_Tg' : accuracy_Tg, 'prec_Tm' :prec_Tm, 'recall_Tm' : recall_Tm, 'accuracy_Tm' : accuracy_Tm }, columns=['prec_Tg','recall_Tg', 'accuracy_Tg', 'prec_Tm','recall_Tm', 'accuracy_Tm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_performance['f1_score_Tg'] = 2*df_performance.prec_Tg*df_performance.recall_Tg/(df_performance.prec_Tg + df_performance.recall_Tg)\n",
    "df_performance['f1_score_Tm'] = 2*df_performance.prec_Tm*df_performance.recall_Tm/(df_performance.prec_Tm + df_performance.recall_Tm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prec_Tg</th>\n",
       "      <th>recall_Tg</th>\n",
       "      <th>accuracy_Tg</th>\n",
       "      <th>prec_Tm</th>\n",
       "      <th>recall_Tm</th>\n",
       "      <th>accuracy_Tm</th>\n",
       "      <th>f1_score_Tg</th>\n",
       "      <th>f1_score_Tm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.965015</td>\n",
       "      <td>0.837975</td>\n",
       "      <td>0.838641</td>\n",
       "      <td>0.969466</td>\n",
       "      <td>0.798742</td>\n",
       "      <td>0.827751</td>\n",
       "      <td>0.897019</td>\n",
       "      <td>0.875862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.944751</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.842887</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>0.734568</td>\n",
       "      <td>0.765550</td>\n",
       "      <td>0.902375</td>\n",
       "      <td>0.829268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.764331</td>\n",
       "      <td>0.973451</td>\n",
       "      <td>0.696203</td>\n",
       "      <td>0.755981</td>\n",
       "      <td>0.841202</td>\n",
       "      <td>0.811808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.967456</td>\n",
       "      <td>0.799511</td>\n",
       "      <td>0.802548</td>\n",
       "      <td>0.959016</td>\n",
       "      <td>0.717791</td>\n",
       "      <td>0.755981</td>\n",
       "      <td>0.875502</td>\n",
       "      <td>0.821053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.753181</td>\n",
       "      <td>0.759574</td>\n",
       "      <td>0.949580</td>\n",
       "      <td>0.729032</td>\n",
       "      <td>0.770335</td>\n",
       "      <td>0.839716</td>\n",
       "      <td>0.824818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    prec_Tg  recall_Tg  accuracy_Tg   prec_Tm  recall_Tm  accuracy_Tm  \\\n",
       "0  0.965015   0.837975     0.838641  0.969466   0.798742     0.827751   \n",
       "1  0.944751   0.863636     0.842887  0.952000   0.734568     0.765550   \n",
       "2  0.980000   0.736842     0.764331  0.973451   0.696203     0.755981   \n",
       "3  0.967456   0.799511     0.802548  0.959016   0.717791     0.755981   \n",
       "4  0.948718   0.753181     0.759574  0.949580   0.729032     0.770335   \n",
       "\n",
       "   f1_score_Tg  f1_score_Tm  \n",
       "0     0.897019     0.875862  \n",
       "1     0.902375     0.829268  \n",
       "2     0.841202     0.811808  \n",
       "3     0.875502     0.821053  \n",
       "4     0.839716     0.824818  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prec_Tg        0.961188\n",
       "recall_Tg      0.798229\n",
       "accuracy_Tg    0.801596\n",
       "prec_Tm        0.960703\n",
       "recall_Tm      0.735267\n",
       "accuracy_Tm    0.775120\n",
       "f1_score_Tg    0.871163\n",
       "f1_score_Tm    0.832562\n",
       "dtype: float32"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_performance.mean(axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 ('.venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "output_auto_scroll": true,
  "vscode": {
   "interpreter": {
    "hash": "a686d76ec85f590216c9e7e08a09f9fc1c5b481b97ecdbc5e95356f9feef4f2c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
